{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing module\n",
    "from geopy.geocoders import Nominatim\n",
    "from timezonefinder import TimezoneFinder\n",
    "from pytz import timezone\n",
    "import pandas as pd\n",
    "\n",
    "def getTimezone(location: str) -> str:\n",
    "    # initialize Nominatim API\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    \n",
    "    # getting Latitude and Longitude\n",
    "    location = geolocator.geocode(location)\n",
    "\n",
    "    # pass the Latitude and Longitude\n",
    "    # into a timezone_at\n",
    "    # and it return timezone\n",
    "    obj = TimezoneFinder()\n",
    "    result = obj.timezone_at(lng=location.longitude, lat=location.latitude)\n",
    "    return result\n",
    "\n",
    "def tzDiff(date, zone1, zone2):\n",
    "    '''\n",
    "    Returns the difference in seconds between zone1 and zone2\n",
    "    for a given date.\n",
    "    '''\n",
    "    tz1, tz2 = timezone(zone1), timezone(zone2)\n",
    "    date = pd.to_datetime(date)\n",
    "\n",
    "    if (tz1.localize(date) > tz2.localize(date).astimezone(tz1)):\n",
    "        return (tz1.localize(date) - tz2.localize(date).astimezone(tz1)).seconds\n",
    "    else:\n",
    "        return -(tz2.localize(date) - tz1.localize(date).astimezone(tz2)).seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep = datetime(2021, 8, 12, 15, 55)\n",
    "arr = datetime(2021, 8, 12, 17, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'longitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-e6b2af5fc420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTimezone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DEN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetTimezone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OAK'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-dec5893a01aa>\u001b[0m in \u001b[0;36mgetTimezone\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# and it return timezone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimezoneFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimezone_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'longitude'"
     ]
    }
   ],
   "source": [
    "tz1, tz2 = getTimezone('DEN'), getTimezone('OAK')\n",
    "tz1, tz2 = timezone(tz1), timezone(tz2)\n",
    "date = pd.to_datetime(dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('-1 days +21:00:00')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tz2.localize(date) -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10800"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tz2.localize(date) - tz1.localize(date).astimezone(tz2)).seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLongestChain(chain):\n",
    "    \"\"\"Return the longest sequence of connected pairs in chain\n",
    "    >>> findLongestChain(['OAK', 'DEN', 'OAK', 'DEN', 'DEN', 'OAK'])\n",
    "    [('OAK', 'DEN'), ('DEN', 'OAK')]\n",
    "    \"\"\"\n",
    "    if len(chain) == 0:\n",
    "        return None\n",
    "    grouped = []\n",
    "    for i in range(0,len(chain)-1,2):\n",
    "        grouped.append((chain[i], chain[i+1]))\n",
    "    end, prev = 0, grouped[0]\n",
    "    curr_len, max_len = 0, 0\n",
    "    for i, v in enumerate(grouped):\n",
    "        if prev[1] == v[0]:\n",
    "            curr_len += 1\n",
    "        else:\n",
    "            curr_len = 1\n",
    "        if curr_len > max_len:\n",
    "            max_len = curr_len\n",
    "            end = i + 1\n",
    "        prev = v\n",
    "    return grouped[end - max_len:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('OAK', 'DEN'), ('OAK', 'DEN'), ('DEN', 'OAK'), ('FLY', 'SWA')]\n",
      "('OAK', 'DEN') ('OAK', 'DEN') 1\n",
      "('OAK', 'DEN') ('OAK', 'DEN') 1\n",
      "('OAK', 'DEN') ('DEN', 'OAK') 2\n",
      "('DEN', 'OAK') ('FLY', 'SWA') 2\n",
      "3 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('OAK', 'DEN'), ('DEN', 'OAK')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findLongestChain(['OAK', 'DEN', 'OAK', 'DEN', 'DEN', 'OAK', 'FLY', 'SWA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file1 = open('data/airport_codes_full.txt', 'r')\n",
    "Lines = file1.readlines()\n",
    " \n",
    "count = 0\n",
    "# Strips the newline character\n",
    "for line in Lines:\n",
    "    count += 1\n",
    "#     print(\"Line{}: {}\".format(count, line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lines[1][5:-6].strip().split(\",\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lines[1][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "codes = dict()\n",
    "for line in Lines[1:]:\n",
    "    codes[line[:3]] = line[5:-6].strip().split(\",\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'OAK' in codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes['OAK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open('data/airport_codes.pickle', 'wb')\n",
    "pickle.dump(codes, file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open('data/airport_codes.pickle', 'rb')\n",
    "test = pickle.load(file2)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'JFK' in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_unique(k,v,d):\n",
    "    if k in d:\n",
    "        print(f\"{k} already exists\")\n",
    "    else:\n",
    "        d[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file1 = open('data/airline_codes.txt', 'r')\n",
    "Lines = file1.readlines()\n",
    "\n",
    "codes = dict()\n",
    " \n",
    "for i in range(0,len(Lines), 3):\n",
    "#     print(\"Line{}: {}\".format(count, line.strip()))\n",
    "    name, code = Lines[i].strip(), Lines[i+2].strip().lower()\n",
    "    if '/' in code:\n",
    "        stripped = [s.strip() for s in code.split('/')]\n",
    "        for c in stripped:\n",
    "            add_unique(c,name,codes)\n",
    "    else:\n",
    "        add_unique(code, name, codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "codes[\"alaska\"] = 'Alaska Airlines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open('data/airline_codes.pickle', 'wb')\n",
    "pickle.dump(codes, file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open('data/airline_codes.pickle', 'rb')\n",
    "test = pickle.load(file2)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "bool(re.match(\"\\d{1,2}/\\d{2}/(\\d{2}|\\d{4})\", '08/09/2021'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
